Efficient data handling is widely used in machine learning especially with the increasing prevalence of large and sparse datasets. In this paper, we explore improving sparse matrix operation efficiency using the Compressed Sparse Row (CSR) format. Focusing on Linear Regression techniques and Singular Value Decomposition (SVD), we investigate methods to optimize these operations for sparse matrices. In the process, we explore an application of the Lanczos algorithm in efficiently computing a lowâ€“rank approximation of SVD for sparse matrices. Our approach demonstrates notable improvements and thus can contribute to a wide array of practices done in larger scales by data engineers.
